{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pytesseract import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ingredients: Corn flour, sugar, peanut butter\\n(peanuts, dextrose. hydrogenated vegetable oil\\n[cottonseed and rapeseed oil]**, salt), oat\\nflour, rice flour, coconut oil, salt, caramel color,\\nniacinamide*, reduced iron, zinc oxide, BHT (a\\nPreservative), thiamin mononitrate*, pyridoxine\\n\\nhydrochloride*, riboflavin*, folic acid*.\\n“One of the B vitamins\\n\\nily insignificant amount of trans fat\\nONTAINS PEANUT INGREDIENTS.\\n\\n**Adds a dietar\\nC'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('downloads/test2.jpg')\n",
    "img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "# Convert to gray\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply dilation and erosion to remove some noise\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "img = cv2.dilate(img, kernel, iterations=1)\n",
    "img = cv2.erode(img, kernel, iterations=1)\n",
    "# Apply blur to smooth out the edges\n",
    "img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "text = image_to_string(img)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pe es\\n(GREDIENTS: Whole grain rolled oats*,\\nFUR amet ems elim bl\\nyeanuts*, Fair Trade dark chocolate chunks*\\n(cane sugar*, unsweetened chocolate*\\nCeolcor Mo Nac UNC MLM Ce aol ey\\npowder*, rice starch*, sea salt, flavors* :\\n(chocolate, vanilla), honey*, tocophero|,\\n(vitamin E). *Organic. Contains peanuts.\\neer ee RUE C CS BUC tee\\n\\ntree nuts, wheat and soy.\\n\\nVEGETARIAN : %'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image = Image.open('downloads/a.png').convert('RGB')\n",
    "open_cv_image = np.array(pil_image) \n",
    "# Convert RGB to BGR \n",
    "img = open_cv_image[:, :, ::-1].copy()\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "img = cv2.dilate(img, kernel, iterations=1)\n",
    "img = cv2.erode(img, kernel, iterations=1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#ret,img = cv2.threshold(cv2.medianBlur(img, 5), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "#img = Image.fromarray(img.astype(np.uint8))\n",
    "\n",
    "text = image_to_string(img,config=\"--psm 6\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'percent Daily values are\\ncalorie diet. Your daily v:\\nor lower depending on\\n\\nona 2,000\\nNay be higher\\nlorie needs:\\n2,500\\n80g\\n\\n209g\\n300mg\\n2,400mg\\n\\nCalories: )\\n\\nLessthan\\nLess than «..j\\ncholesterol Less than 300mg\\nSodium Less than 2,400mg\\nTotal Carbohydrate 300g 375g\\nDietary Fiber 259g 30g\\n\\nINGREDIENTS: TOMATO PUREE (WATER,\\nTOMATO PASTE), TOMATOES, DICED TOMATOES\\nIN TOMATO JUICE, MUSHROOMS, SUGAR,\\nSOYBEAN OIL. SALT, DRIED GREEN BELL\\nPEPPER, DRIED GARLIC, SPICES, OLIVE OIL,\\nvis ONION. DRIED CELERY, ROMANO Olas\\nCau a0n (aS QV A Ges: ae ENZYMES).\\nEST\\n\\nTotal Fat\\nSat Fat\\n\\n \\n\\n“GER CO.\\n\\n“mtr\\n\\nMs aus\\n\\n+E PASTA:\\nres es\\nReea hug\\n\\nayeh\\nIan\\n\\n \\n\\n  \\n\\nrh ood\\n\\n \\n\\nats\\nPan a\\na repiace*\\n\\n \\n \\n\\nni'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image = Image.open('downloads/Input Images/a.jpg').convert('RGB')\n",
    "open_cv_image = np.array(pil_image) \n",
    "# Convert RGB to BGR \n",
    "img = open_cv_image[:, :, ::-1].copy()\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "img = cv2.dilate(img, kernel, iterations=1)\n",
    "img = cv2.erode(img, kernel, iterations=1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret,img = cv2.threshold(cv2.medianBlur(img, 5), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "img = Image.fromarray(img.astype(np.uint8))\n",
    "\n",
    "text = image_to_string(img,config=\"--psm 3\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'percent Daily values are calorie diet. Your daily v: or lower depending on  ona 2,000 Nay be higher lorie needs: 2,500 80g  209g 300mg 2,400mg  Calories: )  Lessthan Less than «..j cholesterol Less than 300mg Sodium Less than 2,400mg Total Carbohydrate 300g 375g Dietary Fiber 259g 30g  INGREDIENTS: TOMATO PUREE (WATER, TOMATO PASTE), TOMATOES, DICED TOMATOES IN TOMATO JUICE, MUSHROOMS, SUGAR, SOYBEAN OIL. SALT, DRIED GREEN BELL PEPPER, DRIED GARLIC, SPICES, OLIVE OIL, vis ONION. DRIED CELERY, ROMANO Olas Cau a0n (aS QV A Ges: ae ENZYMES). EST  Total Fat Sat Fat     “GER CO.  “mtr  Ms aus  +E PASTA: res es Reea hug  ayeh Ian         rh ood     ats Pan a a repiace*       ni'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/pranavraj\n",
      "[nltk_data]     1/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/pranavraj\n",
      "[nltk_data]     1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'percent daily values are calorie diet your daily v or lower depending on ona , nay be higher lorie needs , g g mg ,mg calories lessthan less than j cholesterol less than mg sodium less than ,mg total carbohydrate g g dietary fiber g g  tomato puree water, tomato paste, tomatoes, diced tomatoes in tomato juice, mushrooms, sugar, soybean oil salt, dried green bell pepper, dried garlic, spices, olive oil, vis onion dried celery, romano olas cau an as qv a ges ae enzymes est total fat sat fat ger co mtr ms aus e pasta res es reea hug ayeh ian rh ood ats pan a a repiace ni'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = re.sub (r'([^a-zA-Z,\\s]+?)', '', text)\n",
    "text = text.lower()\n",
    "text = (\" \".join(text.split()))\n",
    "\n",
    "\n",
    "for ch in ['ingredients','ingredient']:\n",
    "    if ch in text:\n",
    "        text = text.replace(ch,\"\")\n",
    "\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.metrics import *\n",
    "from nltk.util import ngrams\n",
    "import enchant  # spell checker library pyenchant\n",
    "from enchant.checker import SpellChecker\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "spell_dictionary = enchant.Dict('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class string_similarity:\n",
    "    \n",
    "    def __init__(self,dictionary):\n",
    "        \n",
    "        self.dictionary = dictionary\n",
    "        self.check = SpellChecker(\"en_US\")\n",
    "        self.stemmer = PorterStemmer()\n",
    "        \n",
    "    '''\n",
    "    suggest words according to input word\n",
    "    '''    \n",
    "    def suggest_words(self,word):\n",
    "        return self.check.suggest(word)\n",
    "    \n",
    "    '''\n",
    "    Compute minimum edit distance between two strings\n",
    "    Operations performed: deletion, insertion and substitution\n",
    "       \n",
    "    '''\n",
    "    def levenshtein_distance(self,s1,s2):\n",
    "        \n",
    "        # nltk already have implemeted function\n",
    "        \n",
    "        distance_btw_strings = edit_distance(s1,s2)\n",
    "        \n",
    "        return distance_btw_strings\n",
    "    \n",
    "    '''\n",
    "    Given word and value of n(denotes how many grams of text)\n",
    "    n = 1 means unigram\n",
    "    n = 2 means bigram and so on\n",
    "    '''\n",
    "    def ngram(self,word,n):\n",
    "        \n",
    "        grams = list(ngrams(word,n))\n",
    "    \n",
    "        return grams\n",
    "    \n",
    "    '''\n",
    "    Takes sentence as input, identifies incorrect word \n",
    "    according to dictionary provided by pyenchant library\n",
    "    returns correct word with least distance using levenshtein distance, but sometimes this is not optimal too\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    Takes input as sentence and returns list of misspelled words\n",
    "    '''\n",
    "    \n",
    "    def check_mistakes_in_sentence(self,sentence):\n",
    "        \n",
    "        misspelled_words = []\n",
    "        \n",
    "        self.check.set_text(sentence)\n",
    "        \n",
    "        for err in self.check:\n",
    "            misspelled_words.append(err.word)\n",
    "            \n",
    "        if len(misspelled_words) == 0:\n",
    "            print (\"No mistakes found\")\n",
    "        return misspelled_words\n",
    "    \n",
    "    '''\n",
    "    Jaccard correlation coefficient computes\n",
    "    similarity between two terms\n",
    "    '''\n",
    "    \n",
    "    def jaccard(self,a,b):\n",
    "\n",
    "        union = list(set(a+b))\n",
    "        intersection = list(set(a) - (set(a)-set(b)))\n",
    "        jaccard_coeff = float(len(intersection))/len(union)\n",
    "        return jaccard_coeff\n",
    "    \n",
    "    '''\n",
    "    Take incorrect word as input and \n",
    "    returns closely suggested words\n",
    "    '''\n",
    "    \n",
    "    def minimumEditDistance_spell_corrector(self,word):\n",
    "        \n",
    "        max_distance = 2\n",
    "        if (self.dictionary.check(word)):\n",
    "            return word\n",
    "        suggested_words = self.suggest_words(word)\n",
    "        \n",
    "        num_modified_characters = []\n",
    "        \n",
    "        if suggested_words != 0:\n",
    "            \n",
    "            for sug_words in suggested_words:\n",
    "                num_modified_characters.append(self.levenshtein_distance(word,sug_words))\n",
    "                \n",
    "            minimum_edit_distance = min(num_modified_characters)\n",
    "            best_arg = num_modified_characters.index(minimum_edit_distance)\n",
    "            if max_distance > minimum_edit_distance:\n",
    "                best_suggestion = suggested_words[best_arg]\n",
    "                return best_suggestion\n",
    "            else:\n",
    "                return word\n",
    "        else:\n",
    "            return word\n",
    "        \n",
    "    '''\n",
    "    takes word as input and return closely corrected word\n",
    "    '''\n",
    "    \n",
    "    def ngram_spell_corrector(self,word):\n",
    "        \n",
    "        max_distance = 2\n",
    "        if (self.dictionary.check(word)):\n",
    "            return word\n",
    "        suggested_words = self.suggest_words(word)\n",
    "        \n",
    "        num_modified_characters = []\n",
    "       \n",
    "        max_jaccard = []\n",
    "        list_of_sug_words = []\n",
    "        if suggested_words != 0:\n",
    "            \n",
    "            word_ngrams = self.ngram(word,2)\n",
    "\n",
    "            for sug_words in suggested_words:\n",
    "\n",
    "                if (self.levenshtein_distance(word,sug_words)) < 3 :\n",
    "\n",
    "                    sug_ngrams = self.ngram(sug_words,2)\n",
    "                    jac = self.jaccard(word_ngrams,sug_ngrams)\n",
    "                    max_jaccard.append(jac)\n",
    "                    list_of_sug_words.append(sug_words)\n",
    "            highest_jaccard = max(max_jaccard)\n",
    "            best_arg = max_jaccard.index(highest_jaccard)\n",
    "            word = list_of_sug_words[best_arg]\n",
    "            return word\n",
    "        else:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pranavraj\n",
      "[nltk_data]     1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gradients', 'whole', 'grain', 'rolled', 'oats', 'e', 'fur', 'met', 'ems', 'elm', 'bl', 'peanuts', 'e', 'fair', 'trade', 'dark', 'chocolate', 'chunks', 'cane', 'Ty', 'see', 'note', 'y', 'utter', 'e', 'vanilla', 'e', 'fair', 'trade', 'c', 'aa', 'rice', 'starch', 'e', 'sea', 'salt', 'e', 'sine', 'chocolate', 'e', 'vanilla', 'e', 'honey', 'e', 'tocophero', 'e', 'vitamin', 'e', 'organic', 'contains', 'peanuts', 'fart', 'es', 'arcs', 'mu', 'u', 'tree', 'nuts', 'e', 'wheat', 'and', 'soy', 'vegetarian', 'on']\n"
     ]
    }
   ],
   "source": [
    "sentence1 = text\n",
    "word_tokenize = nltk.word_tokenize(sentence1)\n",
    "obj = string_similarity(spell_dictionary)\n",
    "correct_sentence = []\n",
    "for misspelled_words in word_tokenize:\n",
    "    correct_sentence.append(obj.minimumEditDistance_spell_corrector(misspelled_words))\n",
    "print (correct_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent daily values are calorie diet your daily v or lower depending on on , nay be higher lore needs , g g my ,my calorie lessthan less than j cholestrol less than my sodium less than ,my total carbohydrates g g dietary finer g g  tomato pure water, tomato paste, potatoes, died potatoes in tomato juice, mushrooms, sugar, soybean oil salt, dried green bell pepper, dried garlic, spaces, olive oil, vis onion dried every, roman alas can an as iv a yes a enzymes est total fat sat fat her co mr ms as e past yes es reed hug aye in oh old as pan a a replace ni\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "correct_text = TextBlob(text)\n",
    "print(correct_text.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'percent daily values are calorie diet your daily v or lower depending on ona , nay be higher lorie needs , g g mg ,mg calories lessthan less than j cholesterol less than mg sodium less than ,mg total carbohydrate g g dietary fiber g g  tomato puree water, tomato paste, tomatoes, diced tomatoes in tomato juice, mushrooms, sugar, soybean oil salt, dried green bell pepper, dried garlic, spices, olive oil, vis onion dried celery, romano olas cau an as qv a ges ae enzymes est total fat sat fat ger co mtr ms aus e pasta res es reea hug ayeh ian rh ood ats pan a a repiace ni'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-137-62a70845a4f8>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-137-62a70845a4f8>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    if w.lower() in words or not w.isalpha())\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#words = set(nltk.corpus.words.words())\n",
    "\n",
    "#sent = text\n",
    "#text = \" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
    "#       if w.lower() in words or not w.isalpha())\n",
    "\n",
    "\n",
    "#text      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counts = dict()\n",
    "\n",
    "words = text.split(\",\")\n",
    "\n",
    "for word in words:\n",
    "    if len(word) >=2:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'percent daily values are calorie diet your daily v or lower depending on ona ': 1,\n",
       " ' nay be higher lorie needs ': 1,\n",
       " ' g g mg ': 1,\n",
       " 'mg calories lessthan less than j cholesterol less than mg sodium less than ': 1,\n",
       " 'mg total carbohydrate g g dietary fiber g g  tomato puree water': 1,\n",
       " ' tomato paste': 1,\n",
       " ' tomatoes': 1,\n",
       " ' diced tomatoes in tomato juice': 1,\n",
       " ' mushrooms': 1,\n",
       " ' sugar': 1,\n",
       " ' soybean oil salt': 1,\n",
       " ' dried green bell pepper': 1,\n",
       " ' dried garlic': 1,\n",
       " ' spices': 1,\n",
       " ' olive oil': 1,\n",
       " ' vis onion dried celery': 1,\n",
       " ' romano olas cau an as qv a ges ae enzymes est total fat sat fat ger co mtr ms aus e pasta res es reea hug ayeh ian rh ood ats pan a a repiace ni': 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V8 (beverage) : https://en.wikipedia.org/wiki/V8_(beverage)\n",
      "Tomato paste : https://en.wikipedia.org/wiki/Tomato_paste\n",
      "Tomato : https://en.wikipedia.org/wiki/Tomato\n",
      "Tomato sauce : https://en.wikipedia.org/wiki/Tomato_sauce\n",
      "Mushroom : https://en.wikipedia.org/wiki/Mushroom\n",
      "Sugar : https://en.wikipedia.org/wiki/Sugar\n",
      "Yellow soybean paste : https://en.wikipedia.org/wiki/Yellow_soybean_paste\n",
      "Spice : https://en.wikipedia.org/wiki/Spice\n",
      "Olive oil : https://en.wikipedia.org/wiki/Olive_oil\n",
      "Satureja : https://en.wikipedia.org/wiki/Satureja\n"
     ]
    }
   ],
   "source": [
    "URL = dict()\n",
    "Title = []\n",
    "for word in counts:\n",
    "    try:\n",
    "        nb = wikipedia.page(word)\n",
    "   \n",
    "        print(nb.title + \" : \" + nb.url)\n",
    "        #URL[nb.title] = nb.url\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wheat flour': 'https://en.wikipedia.org/wiki/Wheat_flour', 'Iron(II) sulfate': 'https://en.wikipedia.org/wiki/Iron(II)_sulfate', 'B vitamins': 'https://en.wikipedia.org/wiki/B_vitamins', 'Thiamine': 'https://en.wikipedia.org/wiki/Thiamine', 'Riboflavin': 'https://en.wikipedia.org/wiki/Riboflavin', 'Folate': 'https://en.wikipedia.org/wiki/Folate', 'Water': 'https://en.wikipedia.org/wiki/Water', 'High-fructose corn syrup': 'https://en.wikipedia.org/wiki/High-fructose_corn_syrup', 'Cottonseed': 'https://en.wikipedia.org/wiki/Cottonseed', 'Canola oil': 'https://en.wikipedia.org/wiki/Canola_oil', 'Tallow': 'https://en.wikipedia.org/wiki/Tallow', 'Glucose': 'https://en.wikipedia.org/wiki/Glucose', 'Carboxymethyl cellulose': 'https://en.wikipedia.org/wiki/Carboxymethyl_cellulose', 'Whey': 'https://en.wikipedia.org/wiki/Whey', 'Disodium pyrophosphate': 'https://en.wikipedia.org/wiki/Disodium_pyrophosphate', 'Sodium bicarbonate': 'https://en.wikipedia.org/wiki/Sodium_bicarbonate', 'Monocalcium phosphate': 'https://en.wikipedia.org/wiki/Monocalcium_phosphate', 'Flour': 'https://en.wikipedia.org/wiki/Flour', 'Glucose syrup': 'https://en.wikipedia.org/wiki/Glucose_syrup', 'Mono- and diglycerides of fatty acids': 'https://en.wikipedia.org/wiki/Mono-_and_diglycerides_of_fatty_acids', 'Lecithin': 'https://en.wikipedia.org/wiki/Lecithin', 'Polysorbate 80': 'https://en.wikipedia.org/wiki/Polysorbate_80', 'Dextrin': 'https://en.wikipedia.org/wiki/Dextrin', 'Calcium caseinate': 'https://en.wikipedia.org/wiki/Calcium_caseinate', 'Sodium stearoyl lactylate': 'https://en.wikipedia.org/wiki/Sodium_stearoyl_lactylate', 'Wheat gluten (food)': 'https://en.wikipedia.org/wiki/Wheat_gluten_(food)', 'Calcium sulfate': 'https://en.wikipedia.org/wiki/Calcium_sulfate', 'Flavor': 'https://en.wikipedia.org/wiki/Flavor', 'Caramel color': 'https://en.wikipedia.org/wiki/Caramel_color', 'Hostess CupCake': 'https://en.wikipedia.org/wiki/Hostess_CupCake', 'Yellow': 'https://en.wikipedia.org/wiki/Yellow', 'Red': 'https://en.wikipedia.org/wiki/Red'}\n"
     ]
    }
   ],
   "source": [
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
